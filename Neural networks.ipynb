{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9466b8f7-4a07-4a63-ac02-e89644a33bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayur\\AppData\\Local\\Temp\\ipykernel_22008\\3126316404.py:13: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y = y.replace({'yes':1, 'no':0})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "44493    1\n",
       "44494    1\n",
       "44495    1\n",
       "44496    0\n",
       "44497    0\n",
       "Name: y, Length: 44498, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('dataset1.csv')\n",
    "\n",
    "# Check for missing values in the dataset\n",
    "if df.isnull().sum().any():\n",
    "    print(\"Missing values found, filling with column means.\")\n",
    "    df = df.fillna(df.mean())  # Impute missing values with mean\n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "y = y.replace({'yes':1, 'no':0})\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6496c711-11a6-4f94-93a7-41aded871941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8906 - loss: 0.3173 - val_accuracy: 0.9061 - val_loss: 0.2291\n",
      "Epoch 2/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8996 - loss: 0.2380 - val_accuracy: 0.9056 - val_loss: 0.2287\n",
      "Epoch 3/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9040 - loss: 0.2284 - val_accuracy: 0.9079 - val_loss: 0.2263\n",
      "Epoch 4/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9038 - loss: 0.2294 - val_accuracy: 0.9072 - val_loss: 0.2240\n",
      "Epoch 5/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9026 - loss: 0.2266 - val_accuracy: 0.9079 - val_loss: 0.2226\n",
      "Epoch 6/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9011 - loss: 0.2274 - val_accuracy: 0.9079 - val_loss: 0.2246\n",
      "Epoch 7/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9069 - loss: 0.2210 - val_accuracy: 0.9070 - val_loss: 0.2224\n",
      "Epoch 8/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9054 - loss: 0.2224 - val_accuracy: 0.9051 - val_loss: 0.2239\n",
      "Epoch 9/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9032 - loss: 0.2255 - val_accuracy: 0.9079 - val_loss: 0.2235\n",
      "Epoch 10/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9037 - loss: 0.2231 - val_accuracy: 0.9072 - val_loss: 0.2228\n",
      "Epoch 11/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9075 - loss: 0.2194 - val_accuracy: 0.9076 - val_loss: 0.2225\n",
      "Epoch 12/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9070 - loss: 0.2207 - val_accuracy: 0.9064 - val_loss: 0.2248\n",
      "Epoch 13/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9071 - loss: 0.2211 - val_accuracy: 0.9065 - val_loss: 0.2246\n",
      "Epoch 14/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9070 - loss: 0.2189 - val_accuracy: 0.9056 - val_loss: 0.2220\n",
      "Epoch 15/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.2158 - val_accuracy: 0.9069 - val_loss: 0.2306\n",
      "Epoch 16/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9077 - loss: 0.2184 - val_accuracy: 0.9032 - val_loss: 0.2247\n",
      "Epoch 17/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.2092 - val_accuracy: 0.9051 - val_loss: 0.2220\n",
      "Epoch 18/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.2117 - val_accuracy: 0.9052 - val_loss: 0.2228\n",
      "Epoch 19/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9083 - loss: 0.2128 - val_accuracy: 0.9041 - val_loss: 0.2218\n",
      "Epoch 20/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9118 - loss: 0.2112 - val_accuracy: 0.9044 - val_loss: 0.2212\n",
      "Epoch 21/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 0.2109 - val_accuracy: 0.9045 - val_loss: 0.2224\n",
      "Epoch 22/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9091 - loss: 0.2109 - val_accuracy: 0.9029 - val_loss: 0.2269\n",
      "Epoch 23/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2048 - val_accuracy: 0.9046 - val_loss: 0.2221\n",
      "Epoch 24/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2052 - val_accuracy: 0.9046 - val_loss: 0.2241\n",
      "Epoch 25/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9098 - loss: 0.2091 - val_accuracy: 0.9042 - val_loss: 0.2233\n",
      "Epoch 26/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9108 - loss: 0.2043 - val_accuracy: 0.9029 - val_loss: 0.2229\n",
      "Epoch 27/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.2064 - val_accuracy: 0.9049 - val_loss: 0.2220\n",
      "Epoch 28/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9121 - loss: 0.2006 - val_accuracy: 0.9041 - val_loss: 0.2212\n",
      "Epoch 29/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9126 - loss: 0.2029 - val_accuracy: 0.9042 - val_loss: 0.2233\n",
      "Epoch 30/30\n",
      "\u001b[1m1002/1002\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9103 - loss: 0.2069 - val_accuracy: 0.9060 - val_loss: 0.2260\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      3949\n",
      "           1       0.60      0.39      0.47       501\n",
      "\n",
      "    accuracy                           0.90      4450\n",
      "   macro avg       0.76      0.68      0.71      4450\n",
      "weighted avg       0.89      0.90      0.89      4450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),  # 32 neurons in the first layer\n",
    "    Dense(16, activation='relu'),  # 16 neurons in the second layer\n",
    "    Dense(8, activation='relu'),  # 16 neurons in the third layer (new)\n",
    "    Dense(4, activation='relu'),   # 8 neurons in the fourth layer (new)\n",
    "    Dense(1, activation='sigmoid')  # Single output neuron with sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")  # Apply threshold to get binary predictions\n",
    "\n",
    "# Generate and print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2c09803-6512-4ecd-9a38-d29f0a60bc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.5189 - val_accuracy: 0.7096 - val_loss: 0.5218\n",
      "Epoch 2/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.3849 - val_accuracy: 0.7585 - val_loss: 0.4811\n",
      "Epoch 3/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8325 - loss: 0.3745 - val_accuracy: 0.7553 - val_loss: 0.5002\n",
      "Epoch 4/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8398 - loss: 0.3627 - val_accuracy: 0.8161 - val_loss: 0.4261\n",
      "Epoch 5/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8445 - loss: 0.3508 - val_accuracy: 0.8194 - val_loss: 0.4226\n",
      "Epoch 6/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.3524 - val_accuracy: 0.8295 - val_loss: 0.4186\n",
      "Epoch 7/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8474 - loss: 0.3409 - val_accuracy: 0.8032 - val_loss: 0.4556\n",
      "Epoch 8/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8471 - loss: 0.3426 - val_accuracy: 0.8151 - val_loss: 0.4413\n",
      "Epoch 9/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8500 - loss: 0.3396 - val_accuracy: 0.8440 - val_loss: 0.3965\n",
      "Epoch 10/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8503 - loss: 0.3383 - val_accuracy: 0.8343 - val_loss: 0.4067\n",
      "Epoch 11/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8541 - loss: 0.3305 - val_accuracy: 0.8455 - val_loss: 0.3961\n",
      "Epoch 12/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8506 - loss: 0.3372 - val_accuracy: 0.8312 - val_loss: 0.4232\n",
      "Epoch 13/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8528 - loss: 0.3299 - val_accuracy: 0.8153 - val_loss: 0.4458\n",
      "Epoch 14/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8523 - loss: 0.3324 - val_accuracy: 0.8339 - val_loss: 0.4101\n",
      "Epoch 15/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8531 - loss: 0.3301 - val_accuracy: 0.8432 - val_loss: 0.3916\n",
      "Epoch 16/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8538 - loss: 0.3287 - val_accuracy: 0.8438 - val_loss: 0.3964\n",
      "Epoch 17/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8583 - loss: 0.3238 - val_accuracy: 0.8824 - val_loss: 0.3237\n",
      "Epoch 18/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8570 - loss: 0.3234 - val_accuracy: 0.8503 - val_loss: 0.3788\n",
      "Epoch 19/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8571 - loss: 0.3216 - val_accuracy: 0.8442 - val_loss: 0.3880\n",
      "Epoch 20/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8571 - loss: 0.3237 - val_accuracy: 0.8286 - val_loss: 0.4181\n",
      "Epoch 21/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8576 - loss: 0.3219 - val_accuracy: 0.8130 - val_loss: 0.4522\n",
      "Epoch 22/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8577 - loss: 0.3232 - val_accuracy: 0.8014 - val_loss: 0.4732\n",
      "Epoch 23/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8587 - loss: 0.3201 - val_accuracy: 0.8478 - val_loss: 0.3922\n",
      "Epoch 24/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8602 - loss: 0.3185 - val_accuracy: 0.8246 - val_loss: 0.4279\n",
      "Epoch 25/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8598 - loss: 0.3163 - val_accuracy: 0.8320 - val_loss: 0.4154\n",
      "Epoch 26/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8611 - loss: 0.3171 - val_accuracy: 0.8372 - val_loss: 0.4156\n",
      "Epoch 27/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8625 - loss: 0.3113 - val_accuracy: 0.8440 - val_loss: 0.3963\n",
      "Epoch 28/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8640 - loss: 0.3132 - val_accuracy: 0.8410 - val_loss: 0.4051\n",
      "Epoch 29/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8626 - loss: 0.3128 - val_accuracy: 0.8625 - val_loss: 0.3656\n",
      "Epoch 30/30\n",
      "\u001b[1m1777/1777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8646 - loss: 0.3116 - val_accuracy: 0.8672 - val_loss: 0.3559\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91      3949\n",
      "           1       0.42      0.78      0.55       501\n",
      "\n",
      "    accuracy                           0.85      4450\n",
      "   macro avg       0.70      0.82      0.73      4450\n",
      "weighted avg       0.91      0.85      0.87      4450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_smote.shape[1],)),  # 32 neurons in the first layer\n",
    "    #Dense(16, activation='relu'),  # 16 neurons in the second layer\n",
    "    #Dense(8, activation='relu'),  # 16 neurons in the third layer (new)\n",
    "    #Dense(4, activation='relu'),   # 8 neurons in the fourth layer (new)\n",
    "    Dense(1, activation='sigmoid')  # Single output neuron with sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_smote, y_train_smote, epochs=30, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")  # Apply threshold to get binary predictions\n",
    "\n",
    "# Generate and print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dc33fd-4899-45e4-8157-54ddc29c0075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
