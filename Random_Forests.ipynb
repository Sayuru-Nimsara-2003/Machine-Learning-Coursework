{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ed5643f7-35e6-4d3e-a3ba-9f434e07b988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 30)\n",
    "\n",
    "df = pd.read_csv('dataset2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4a8a0896-20ea-4f77-89a6-1ad4f69ecdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_counts = df.y.value_counts()\n",
    "plt.pie(y_counts.values, labels=y_counts.index)\n",
    "plt.title('subscription ratio');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "829a44c8-5cbd-4556-af11-68e894f3f7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "no     39487\n",
       "yes     5011\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4a6d99-7fb4-4845-8038-e99751e9bef8",
   "metadata": {},
   "source": [
    "### Using Random Forests without any resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "18fd6b12-f99d-481b-a03a-1d4fdb7842e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9082022471910113\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.93      0.97      0.95      7898\n",
      "         yes       0.65      0.39      0.49      1002\n",
      "\n",
      "    accuracy                           0.91      8900\n",
      "   macro avg       0.79      0.68      0.72      8900\n",
      "weighted avg       0.90      0.91      0.90      8900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e01932-49d0-4b94-8615-92321b71d305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b27c9996-541a-44eb-a963-23fbea790700",
   "metadata": {},
   "source": [
    "### Using Random Forests with 'SMOTE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cafed3ab-5e9d-405c-aaf9-87c4dc922de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8930337078651686\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.96      0.92      0.94      7898\n",
      "         yes       0.52      0.66      0.58      1002\n",
      "\n",
      "    accuracy                           0.89      8900\n",
      "   macro avg       0.74      0.79      0.76      8900\n",
      "weighted avg       0.91      0.89      0.90      8900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Smote for training set\n",
    "smote = SMOTE(random_state=54)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, random_state=54)\n",
    "rf_classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aaad22-e4c7-41e7-b98a-2b9d534fc431",
   "metadata": {},
   "source": [
    "## Optimizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe69ad24-9dc2-4504-99dd-e59ed6a6cbfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74ce11d8-0e8b-406c-abf5-23dab07f847e",
   "metadata": {},
   "source": [
    "### 1. Identifying overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6b59f4-2a0c-460f-807c-9cea2e4d38ef",
   "metadata": {},
   "source": [
    "#### 1) train vs. test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1c51c398-d3f0-4bb5-b001-9e41a9b41416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Training Classification Report:\n",
      " {'no': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 31589.0}, 'yes': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 31589.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 63178.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 63178.0}}\n",
      "Test Accuracy: 0.8930337078651686\n",
      "Test Classification Report:\n",
      " {'no': {'precision': 0.9557742782152231, 'recall': 0.9221321853633832, 'f1-score': 0.9386518881299136, 'support': 7898.0}, 'yes': {'precision': 0.51953125, 'recall': 0.6636726546906188, 'f1-score': 0.5828220858895705, 'support': 1002.0}, 'accuracy': 0.8930337078651686, 'macro avg': {'precision': 0.7376527641076116, 'recall': 0.792902420027001, 'f1-score': 0.760736987009742, 'support': 8900.0}, 'weighted avg': {'precision': 0.9066601754880711, 'recall': 0.8930337078651686, 'f1-score': 0.8985910497203828, 'support': 8900.0}}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance on training set\n",
    "y_train_pred = rf_classifier.predict(X_train_smote)\n",
    "train_accuracy = accuracy_score(y_train_smote, y_train_pred)\n",
    "train_report = classification_report(y_train_smote, y_train_pred, output_dict=True)\n",
    "\n",
    "# Evaluate performance on test set\n",
    "y_test_pred = rf_classifier.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Training Classification Report:\\n\", train_report)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test Classification Report:\\n\", test_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7216c00f-3d7b-4631-87ea-8ffeb94c4353",
   "metadata": {},
   "source": [
    "#### 2) cross validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "786e6285-286c-4442-945d-2efa381d685a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified CV Scores: [0.89370787 0.89179775 0.89606742 0.89953927 0.89549388]\n",
      "Mean Stratified CV Accuracy: 0.8953212366999953\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "# Initialize Random Forest and SMOTE\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, random_state=54)\n",
    "smote = SMOTE(random_state=54)\n",
    "\n",
    "# Stratified K-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=54)\n",
    "\n",
    "# List to store CV scores\n",
    "cv_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTE to the training data\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model on the resampled training data\n",
    "    rf_classifier.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # Evaluate on the test set (not resampled)\n",
    "    accuracy = rf_classifier.score(X_test, y_test)\n",
    "    cv_scores.append(accuracy)\n",
    "\n",
    "# Convert to numpy array for easier calculation\n",
    "cv_scores = np.array(cv_scores)\n",
    "\n",
    "# Output results\n",
    "print(\"Stratified CV Scores:\", cv_scores)\n",
    "print(\"Mean Stratified CV Accuracy:\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a956edc4-5048-4313-95f1-50a7f8016691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified CV F1 Scores for 'yes' class: [0.59661311 0.57604895 0.58844444 0.60632689 0.58488889]\n",
      "Mean Stratified CV F1 Score for 'yes' class: 0.5904644573984321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "# Initialize Random Forest and SMOTE\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=54)\n",
    "smote = SMOTE(random_state=54)\n",
    "\n",
    "# Stratified K-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=54)\n",
    "\n",
    "# List to store CV scores\n",
    "f1_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTE to the training data\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model on the resampled training data\n",
    "    rf_classifier.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate the F1-Score for the minority class ('yes')\n",
    "    f1 = f1_score(y_test, y_pred, pos_label='yes')  # Use the 'yes' class for minority\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Convert to numpy array for easier calculation\n",
    "f1_scores = np.array(f1_scores)\n",
    "\n",
    "# Output results\n",
    "print(\"Stratified CV F1 Scores for 'yes' class:\", f1_scores)\n",
    "print(\"Mean Stratified CV F1 Score for 'yes' class:\", f1_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dafc0fcd-79a1-4465-9772-5418ddc39789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified CV F1 Scores for 'no' class: [0.94005291 0.93746777 0.94045016 0.94227548 0.93992797]\n",
      "Mean Stratified CV F1 Score for 'no' class: 0.9400348572208952\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "# Initialize Random Forest and SMOTE\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=54)\n",
    "smote = SMOTE(random_state=54)\n",
    "\n",
    "# Stratified K-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=54)\n",
    "\n",
    "# List to store CV scores\n",
    "f1_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTE to the training data\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model on the resampled training data\n",
    "    rf_classifier.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate the F1-Score for the minority class ('yes')\n",
    "    f1 = f1_score(y_test, y_pred, pos_label='no')  # Use the 'yes' class for minority\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Convert to numpy array for easier calculation\n",
    "f1_scores = np.array(f1_scores)\n",
    "\n",
    "# Output results\n",
    "print(\"Stratified CV F1 Scores for 'no' class:\", f1_scores)\n",
    "print(\"Mean Stratified CV F1 Score for 'no' class:\", f1_scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce042aa-5a0b-495c-8faf-4803b343793e",
   "metadata": {},
   "source": [
    "#### 3) Learning Curve Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7673eb2f-ced5-4399-aaa8-8b65ad36ddc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature  Importance\n",
      "9    duration    0.367467\n",
      "14     lcdays    0.127245\n",
      "10   campaign    0.101499\n",
      "5     balance    0.083813\n",
      "0         age    0.066809\n",
      "8     contact    0.042492\n",
      "12   previous    0.039943\n",
      "6     housing    0.034147\n",
      "1         job    0.031852\n",
      "11      pdays    0.031224\n",
      "13   poutcome    0.028126\n",
      "3   education    0.018062\n",
      "2     marital    0.014747\n",
      "7        loan    0.011410\n",
      "4     default    0.001165\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "print(importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4c38c8ba-3106-4357-89ba-2a613d179091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "no     39487\n",
       "yes     5011\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset2.csv')\n",
    "df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ffc3cf5e-d28c-4649-8acd-9ca40d868ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
       "       'loan', 'contact', 'duration', 'campaign', 'pdays', 'previous',\n",
       "       'poutcome', 'y', 'lcdays'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8f6a9098-5619-4ac7-8bc1-de41a0d754ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['marital', 'loan', 'education', 'default', 'poutcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "98f29976-53c4-4fcc-b356-c278456b3ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8908988764044944\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.96      0.92      0.94      7898\n",
      "         yes       0.51      0.67      0.58      1002\n",
      "\n",
      "    accuracy                           0.89      8900\n",
      "   macro avg       0.73      0.79      0.76      8900\n",
      "weighted avg       0.91      0.89      0.90      8900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Smote for training set\n",
    "smote = SMOTE(random_state=54)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, random_state=54, class_weight='balanced')\n",
    "rf_classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3d339e0f-a2bd-480b-9015-ddc297d202f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Training Classification Report:\n",
      " {'no': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 31589.0}, 'yes': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 31589.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 63178.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 63178.0}}\n",
      "Test Accuracy: 0.8908988764044944\n",
      "Test Classification Report:\n",
      " {'no': {'precision': 0.9565045472518782, 'recall': 0.918840212712079, 'f1-score': 0.937294155634485, 'support': 7898.0}, 'yes': {'precision': 0.5118050266565118, 'recall': 0.6706586826347305, 'f1-score': 0.5805615550755939, 'support': 1002.0}, 'accuracy': 0.8908988764044944, 'macro avg': {'precision': 0.734154786954195, 'recall': 0.7947494476734047, 'f1-score': 0.7589278553550395, 'support': 8900.0}, 'weighted avg': {'precision': 0.9064383765061975, 'recall': 0.8908988764044944, 'f1-score': 0.8971316763356076, 'support': 8900.0}}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance on training set\n",
    "y_train_pred = rf_classifier.predict(X_train_smote)\n",
    "train_accuracy = accuracy_score(y_train_smote, y_train_pred)\n",
    "train_report = classification_report(y_train_smote, y_train_pred, output_dict=True)\n",
    "\n",
    "# Evaluate performance on test set\n",
    "y_test_pred = rf_classifier.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Training Classification Report:\\n\", train_report)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test Classification Report:\\n\", test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d949b67a-e5fc-4958-a88c-5888281aad67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified CV Scores: [0.89651685 0.89303371 0.89123596 0.89830318 0.89605574]\n",
      "Mean Stratified CV Accuracy: 0.8950290867172301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "# Initialize Random Forest and SMOTE\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, random_state=54)\n",
    "smote = SMOTE(random_state=54)\n",
    "\n",
    "# Stratified K-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=54)\n",
    "\n",
    "# List to store CV scores\n",
    "cv_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTE to the training data\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model on the resampled training data\n",
    "    rf_classifier.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # Evaluate on the test set (not resampled)\n",
    "    accuracy = rf_classifier.score(X_test, y_test)\n",
    "    cv_scores.append(accuracy)\n",
    "\n",
    "# Convert to numpy array for easier calculation\n",
    "cv_scores = np.array(cv_scores)\n",
    "\n",
    "# Output results\n",
    "print(\"Stratified CV Scores:\", cv_scores)\n",
    "print(\"Mean Stratified CV Accuracy:\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e4e7a40c-eec2-4b83-8e64-ab76ede14178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified CV F1 Scores for 'yes' class: [0.60051546 0.5734327  0.57867133 0.604121   0.59304348]\n",
      "Mean Stratified CV F1 Score for 'yes' class: 0.5899567950730574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "# Initialize Random Forest and SMOTE\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=54)\n",
    "smote = SMOTE(random_state=54)\n",
    "\n",
    "# Stratified K-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=54)\n",
    "\n",
    "# List to store CV scores\n",
    "f1_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTE to the training data\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model on the resampled training data\n",
    "    rf_classifier.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate the F1-Score for the minority class ('yes')\n",
    "    f1 = f1_score(y_test, y_pred, pos_label='yes')  # Use the 'yes' class for minority\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Convert to numpy array for easier calculation\n",
    "f1_scores = np.array(f1_scores)\n",
    "\n",
    "# Output results\n",
    "print(\"Stratified CV F1 Scores for 'yes' class:\", f1_scores)\n",
    "print(\"Mean Stratified CV F1 Score for 'yes' class:\", f1_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e721337e-ec54-4e10-8064-be1ea3eab6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified CV F1 Scores for 'no' class: [0.93989142 0.93730266 0.93785456 0.94180576 0.93960511]\n",
      "Mean Stratified CV F1 Score for 'no' class: 0.9392919027949838\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "# Initialize Random Forest and SMOTE\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=54)\n",
    "smote = SMOTE(random_state=54)\n",
    "\n",
    "# Stratified K-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=54)\n",
    "\n",
    "# List to store CV scores\n",
    "f1_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Apply SMOTE to the training data\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train the model on the resampled training data\n",
    "    rf_classifier.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate the F1-Score for the minority class ('yes')\n",
    "    f1 = f1_score(y_test, y_pred, pos_label='no')  # Use the 'yes' class for minority\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Convert to numpy array for easier calculation\n",
    "f1_scores = np.array(f1_scores)\n",
    "\n",
    "# Output results\n",
    "print(\"Stratified CV F1 Scores for 'no' class:\", f1_scores)\n",
    "print(\"Mean Stratified CV F1 Score for 'no' class:\", f1_scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda0ef1b-4081-409d-844d-68fc738f90ac",
   "metadata": {},
   "source": [
    "### 2) Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c023f6f9-627f-4a92-aa66-40d9fbe74504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayur\\AppData\\Local\\Temp\\ipykernel_7272\\601479920.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['y'] = df['y'].replace({'yes':1, 'no':0})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8908988764044944\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      7898\n",
      "           1       0.51      0.67      0.58      1002\n",
      "\n",
      "    accuracy                           0.89      8900\n",
      "   macro avg       0.73      0.79      0.76      8900\n",
      "weighted avg       0.91      0.89      0.90      8900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset2.csv\")\n",
    "df = df.drop(columns=['marital', 'loan', 'education', 'default', 'poutcome'])\n",
    "df['y'] = df['y'].replace({'yes':1, 'no':0})\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Smote for training set\n",
    "smote = SMOTE(random_state=54)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, random_state=54, class_weight='balanced')\n",
    "rf_classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f583aa97-41fc-4827-b9b5-324b567750ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "70 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "37 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sayur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\sayur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\sayur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\sayur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "33 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sayur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\sayur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\sayur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\sayur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\sayur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "C:\\Users\\sayur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan 0.93039112        nan 0.93576498        nan        nan\n",
      " 0.90367061 0.9285762  0.93126621        nan 0.94263198 0.9348431\n",
      " 0.93550187 0.90483858 0.93442135 0.904018          nan 0.93734612\n",
      "        nan 0.93358869 0.93719496 0.94077016 0.94063487 0.93895716\n",
      " 0.9352725         nan        nan        nan        nan 0.93993346\n",
      "        nan 0.90343708 0.92950554 0.93998554        nan 0.93552517\n",
      " 0.93112957        nan 0.93735825 0.94263198]\n",
      "  warnings.warn(\n",
      "C:\\Users\\sayur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan 0.92931112        nan 0.93510429        nan        nan\n",
      " 0.90086754 0.92742748 0.93029244        nan 0.94252782 0.93413878\n",
      " 0.93488271 0.90213383 0.93342643 0.9012949         nan 0.93686127\n",
      "        nan 0.93296747 0.93670299 0.94037515 0.94020101 0.93877648\n",
      " 0.93461364        nan        nan        nan        nan 0.93978951\n",
      "        nan 0.9005035  0.92834559 0.9396154         nan 0.93469272\n",
      " 0.93015002        nan 0.93686124 0.94252782]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 175}\n",
      "Best F1 Score: 0.942631981788919\n",
      "Random Search Results: {'mean_fit_time': array([4.35327053e-02, 1.53814958e+01, 2.57936478e-02, 3.88762907e+01,\n",
      "       1.20610714e-02, 1.04272366e-02, 1.81378800e+01, 1.00757534e+01,\n",
      "       1.07025813e+01, 1.05689526e-02, 3.33090435e+01, 2.70340477e+01,\n",
      "       3.60655447e+01, 6.95850957e+01, 3.49765331e+01, 7.17739938e+01,\n",
      "       2.93327808e-02, 5.11901816e+01, 2.32605934e-02, 2.82615628e+01,\n",
      "       4.10919761e+01, 8.36886886e+01, 4.21929069e+01, 1.07729408e+02,\n",
      "       1.03531119e+02, 1.61351204e-02, 9.41429138e-03, 1.57722473e-02,\n",
      "       2.52312183e-02, 8.59078331e+01, 4.92177963e-02, 5.05777346e+01,\n",
      "       4.82179162e+01, 5.34088351e+01, 2.01154232e-02, 5.03634008e+01,\n",
      "       4.18747629e+01, 3.10354233e-02, 3.50674372e+01, 4.27400187e+01]), 'std_fit_time': array([1.25794260e-02, 6.24572737e-01, 1.61079667e-02, 7.82205520e-01,\n",
      "       4.46815214e-03, 6.49986095e-03, 2.97844570e-01, 1.77016868e-01,\n",
      "       3.59579157e-01, 2.16498134e-03, 4.10868609e+00, 3.65406813e+00,\n",
      "       5.29463285e+00, 2.89682533e+00, 5.16498602e-01, 1.37990667e+00,\n",
      "       1.91387373e-02, 5.01673698e-01, 2.90596664e-02, 5.53378368e-01,\n",
      "       4.60959925e-01, 1.05326997e+00, 4.34898539e-01, 8.30540812e-01,\n",
      "       1.41534265e+00, 3.37344872e-03, 7.01379492e-03, 2.35079297e-04,\n",
      "       1.96636230e-02, 1.02464682e+00, 2.24371748e-02, 9.46541512e-01,\n",
      "       5.53893925e-01, 3.29949587e-01, 1.38543276e-02, 5.36026161e-01,\n",
      "       2.28121531e-01, 2.61548052e-02, 3.87336119e+00, 1.94989669e+00]), 'mean_score_time': array([0.        , 0.29114776, 0.        , 0.55505757, 0.        ,\n",
      "       0.        , 0.3161592 , 0.18695154, 0.221106  , 0.        ,\n",
      "       0.99164243, 0.80216727, 0.72181005, 0.88199863, 0.72647734,\n",
      "       0.92788744, 0.        , 0.76857123, 0.        , 0.59572954,\n",
      "       0.60785117, 1.22175717, 0.60849152, 1.57139864, 1.47294497,\n",
      "       0.        , 0.        , 0.        , 0.        , 1.29969888,\n",
      "       0.        , 0.90791068, 0.97845759, 0.8270031 , 0.        ,\n",
      "       0.95162048, 0.74691439, 0.        , 0.33684511, 0.53945947]), 'std_score_time': array([0.        , 0.02682977, 0.        , 0.04730424, 0.        ,\n",
      "       0.        , 0.02461022, 0.01307879, 0.01496464, 0.        ,\n",
      "       0.3039855 , 0.20887261, 0.05571797, 0.09020715, 0.03247636,\n",
      "       0.04814732, 0.        , 0.0471605 , 0.        , 0.05483373,\n",
      "       0.04195069, 0.07494713, 0.06582352, 0.04568168, 0.07683812,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.04716498,\n",
      "       0.        , 0.02029261, 0.03308027, 0.05002746, 0.        ,\n",
      "       0.18096356, 0.08949353, 0.        , 0.04852882, 0.01647642]), 'param_bootstrap': masked_array(data=[True, True, True, False, False, False, True, True,\n",
      "                   True, True, False, False, False, False, True, False,\n",
      "                   True, False, True, True, False, False, False, False,\n",
      "                   False, True, True, True, False, False, True, True,\n",
      "                   True, False, True, True, True, True, False, False],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value=True), 'param_max_depth': masked_array(data=[30, 20, 30, None, 10, None, 10, 30, None, 10, None, 20,\n",
      "                   None, 10, 20, 10, 30, None, 30, None, 30, 20, 20, 30,\n",
      "                   None, 20, None, 20, 30, None, 20, 10, None, 30, 30,\n",
      "                   None, None, 10, 30, None],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value=np.str_('?'),\n",
      "            dtype=object), 'param_max_features': masked_array(data=['auto', 'sqrt', 'auto', 'sqrt', 'auto', 'auto', 'log2',\n",
      "                   'log2', 'log2', 'auto', 'sqrt', 'log2', 'sqrt', 'sqrt',\n",
      "                   'sqrt', 'sqrt', 'auto', 'sqrt', 'auto', 'log2', 'log2',\n",
      "                   'log2', 'sqrt', 'sqrt', 'log2', 'auto', 'auto', 'auto',\n",
      "                   'auto', 'sqrt', 'auto', 'sqrt', 'sqrt', 'sqrt', 'auto',\n",
      "                   'log2', 'log2', 'auto', 'log2', 'sqrt'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value=np.str_('?'),\n",
      "            dtype=object), 'param_min_samples_leaf': masked_array(data=[3, 3, 4, 4, 1, 1, 2, 4, 3, 4, 1, 4, 4, 2, 2, 3, 2, 3,\n",
      "                   1, 1, 3, 1, 1, 1, 4, 3, 2, 3, 3, 1, 4, 2, 4, 2, 3, 2,\n",
      "                   3, 1, 3, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value=999999), 'param_min_samples_split': masked_array(data=[4, 8, 9, 5, 5, 4, 7, 9, 6, 7, 3, 6, 5, 5, 5, 9, 9, 6,\n",
      "                   6, 9, 4, 4, 5, 9, 9, 6, 8, 8, 8, 8, 6, 6, 5, 4, 7, 2,\n",
      "                   7, 4, 7, 3],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value=999999), 'param_n_estimators': masked_array(data=[200, 150, 150, 250, 125, 150, 250, 100, 100, 125, 175,\n",
      "                   150, 125, 250, 125, 250, 200, 125, 200, 100, 100, 200,\n",
      "                   100, 250, 250, 250, 250, 125, 100, 200, 150, 250, 175,\n",
      "                   125, 100, 175, 150, 125, 100, 175],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value=999999), 'params': [{'bootstrap': True, 'max_depth': 30, 'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 200}, {'bootstrap': True, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 150}, {'bootstrap': True, 'max_depth': 30, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 9, 'n_estimators': 150}, {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 250}, {'bootstrap': False, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 125}, {'bootstrap': False, 'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 150}, {'bootstrap': True, 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 7, 'n_estimators': 250}, {'bootstrap': True, 'max_depth': 30, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 9, 'n_estimators': 100}, {'bootstrap': True, 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 100}, {'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 7, 'n_estimators': 125}, {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 175}, {'bootstrap': False, 'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 6, 'n_estimators': 150}, {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 125}, {'bootstrap': False, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 250}, {'bootstrap': True, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 125}, {'bootstrap': False, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 9, 'n_estimators': 250}, {'bootstrap': True, 'max_depth': 30, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 9, 'n_estimators': 200}, {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 125}, {'bootstrap': True, 'max_depth': 30, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 200}, {'bootstrap': True, 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 9, 'n_estimators': 100}, {'bootstrap': False, 'max_depth': 30, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 100}, {'bootstrap': False, 'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 200}, {'bootstrap': False, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}, {'bootstrap': False, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 9, 'n_estimators': 250}, {'bootstrap': False, 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 9, 'n_estimators': 250}, {'bootstrap': True, 'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 250}, {'bootstrap': True, 'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 8, 'n_estimators': 250}, {'bootstrap': True, 'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 125}, {'bootstrap': False, 'max_depth': 30, 'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 100}, {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 200}, {'bootstrap': True, 'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 6, 'n_estimators': 150}, {'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 250}, {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 175}, {'bootstrap': False, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 125}, {'bootstrap': True, 'max_depth': 30, 'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 7, 'n_estimators': 100}, {'bootstrap': True, 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 175}, {'bootstrap': True, 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 7, 'n_estimators': 150}, {'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 125}, {'bootstrap': False, 'max_depth': 30, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 7, 'n_estimators': 100}, {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 175}], 'split0_test_F1': array([       nan, 0.88731592,        nan, 0.88998196,        nan,\n",
      "              nan, 0.86678905, 0.88543784, 0.88682171,        nan,\n",
      "       0.89196584, 0.88836105, 0.88936345, 0.86823811, 0.89259289,\n",
      "       0.86536157,        nan, 0.88812109,        nan, 0.88561554,\n",
      "       0.88861468, 0.89227224, 0.89378494, 0.88693634, 0.88925322,\n",
      "              nan,        nan,        nan,        nan, 0.8882992 ,\n",
      "              nan, 0.86774683, 0.88746242, 0.89160205,        nan,\n",
      "       0.89172183, 0.88651557,        nan, 0.89016771, 0.89196584]), 'split1_test_F1': array([       nan, 0.93916089,        nan, 0.94522118,        nan,\n",
      "              nan, 0.91290518, 0.93983244, 0.94079098,        nan,\n",
      "       0.9529574 , 0.94486024, 0.94432139, 0.91248011, 0.9434308 ,\n",
      "       0.91171798,        nan, 0.94736038,        nan, 0.9434942 ,\n",
      "       0.94663609, 0.95134639, 0.95061634, 0.95030247, 0.94490716,\n",
      "              nan,        nan,        nan,        nan, 0.95043285,\n",
      "              nan, 0.9100801 , 0.93879415, 0.94974375,        nan,\n",
      "       0.94546564, 0.94071026,        nan, 0.94713488, 0.9529574 ]), 'split2_test_F1': array([       nan, 0.94323478,        nan, 0.9497318 ,        nan,\n",
      "              nan, 0.91382188, 0.94129338, 0.94556575,        nan,\n",
      "       0.95846793, 0.94857055, 0.95016866, 0.91452017, 0.94725577,\n",
      "       0.91627412,        nan, 0.95208892,        nan, 0.94852153,\n",
      "       0.95107362, 0.95468139, 0.95433264, 0.95444419, 0.94911097,\n",
      "              nan,        nan,        nan,        nan, 0.95586652,\n",
      "              nan, 0.91398257, 0.94109558, 0.95412703,        nan,\n",
      "       0.94889059, 0.9441896 ,        nan, 0.95162776, 0.95846793]), 'split3_test_F1': array([       nan, 0.94064486,        nan, 0.94686805,        nan,\n",
      "              nan, 0.91518197, 0.9378159 , 0.94119449,        nan,\n",
      "       0.95434983, 0.9461509 , 0.94649701, 0.9161084 , 0.94371698,\n",
      "       0.91639357,        nan, 0.94944381,        nan, 0.94445721,\n",
      "       0.94929037, 0.95226401, 0.95217625, 0.95196372, 0.94650521,\n",
      "              nan,        nan,        nan,        nan, 0.95219797,\n",
      "              nan, 0.9148289 , 0.93991581, 0.95152631,        nan,\n",
      "       0.9451929 , 0.94132067,        nan, 0.94912133, 0.95434983]), 'split4_test_F1': array([       nan, 0.94159914,        nan, 0.9470219 ,        nan,\n",
      "              nan, 0.90965496, 0.93850145, 0.94195815,        nan,\n",
      "       0.95541891, 0.94627277, 0.94715883, 0.91284612, 0.94511031,\n",
      "       0.91034274,        nan, 0.94971639,        nan, 0.945855  ,\n",
      "       0.95036004, 0.9532868 , 0.95226419, 0.95113907, 0.94658595,\n",
      "              nan,        nan,        nan,        nan, 0.95287074,\n",
      "              nan, 0.91054699, 0.94025974, 0.95292855,        nan,\n",
      "       0.94635488, 0.94291173,        nan, 0.94873956, 0.95541891]), 'mean_test_F1': array([       nan, 0.93039112,        nan, 0.93576498,        nan,\n",
      "              nan, 0.90367061, 0.9285762 , 0.93126621,        nan,\n",
      "       0.94263198, 0.9348431 , 0.93550187, 0.90483858, 0.93442135,\n",
      "       0.904018  ,        nan, 0.93734612,        nan, 0.93358869,\n",
      "       0.93719496, 0.94077016, 0.94063487, 0.93895716, 0.9352725 ,\n",
      "              nan,        nan,        nan,        nan, 0.93993346,\n",
      "              nan, 0.90343708, 0.92950554, 0.93998554,        nan,\n",
      "       0.93552517, 0.93112957,        nan, 0.93735825, 0.94263198]), 'std_test_F1': array([       nan, 0.02157823,        nan, 0.02293719,        nan,\n",
      "              nan, 0.01853051, 0.02160199, 0.02228632,        nan,\n",
      "       0.02539789, 0.02327175, 0.02314489, 0.01834584, 0.02095793,\n",
      "       0.01947809,        nan, 0.02465813,        nan, 0.02404629,\n",
      "       0.02433686, 0.02427427, 0.02345472, 0.02604726, 0.02304896,\n",
      "              nan,        nan,        nan,        nan, 0.02587659,\n",
      "              nan, 0.01794132, 0.02103453, 0.02423583,        nan,\n",
      "       0.0219405 , 0.02234028,        nan, 0.02363917, 0.02539789]), 'rank_test_F1': array([27, 20, 27, 11, 27, 27, 25, 22, 18, 27,  1, 15, 13, 23, 16, 24, 27,\n",
      "        9, 27, 17, 10,  3,  4,  7, 14, 27, 27, 27, 27,  6, 27, 26, 21,  5,\n",
      "       27, 12, 19, 27,  8,  1], dtype=int32), 'split0_test_ROC-AUC': array([       nan, 0.89039253,        nan, 0.8937955 ,        nan,\n",
      "              nan, 0.86791706, 0.88849319, 0.89023425,        nan,\n",
      "       0.89688192, 0.89213359, 0.89339981, 0.86949984, 0.89545742,\n",
      "       0.86665084,        nan, 0.892371  ,        nan, 0.88999683,\n",
      "       0.89284584, 0.89640709, 0.89775245, 0.89205445, 0.89308325,\n",
      "              nan,        nan,        nan,        nan, 0.89339981,\n",
      "              nan, 0.86886673, 0.89039253, 0.8960114 ,        nan,\n",
      "       0.89514087, 0.88983856,        nan, 0.89427034, 0.89688192]), 'split1_test_ROC-AUC': array([       nan, 0.93676796,        nan, 0.94325736,        nan,\n",
      "              nan, 0.90899019, 0.93748022, 0.93850902,        nan,\n",
      "       0.95140867, 0.94286167, 0.94230769, 0.90859449, 0.94135802,\n",
      "       0.90764482,        nan, 0.94547325,        nan, 0.94143716,\n",
      "       0.944761  , 0.94966762, 0.94895537, 0.94863881, 0.9429408 ,\n",
      "              nan,        nan,        nan,        nan, 0.94879709,\n",
      "              nan, 0.90582463, 0.93637227, 0.9480057 ,        nan,\n",
      "       0.94341564, 0.93842988,        nan, 0.94531497, 0.95140867]), 'split2_test_ROC-AUC': array([       nan, 0.94119975,        nan, 0.94808484,        nan,\n",
      "              nan, 0.91009813, 0.93922127, 0.94365305,        nan,\n",
      "       0.95726496, 0.94689775, 0.94855967, 0.91096866, 0.94539411,\n",
      "       0.91278886,        nan, 0.95053814,        nan, 0.94681861,\n",
      "       0.94950934, 0.95322887, 0.95291231, 0.95307059, 0.94745173,\n",
      "              nan,        nan,        nan,        nan, 0.95457423,\n",
      "              nan, 0.91017727, 0.93898386, 0.9526749 ,        nan,\n",
      "       0.94713517, 0.94222855,        nan, 0.95014245, 0.95726496]), 'split3_test_ROC-AUC': array([       nan, 0.93866509,        nan, 0.94515492,        nan,\n",
      "              nan, 0.91183534, 0.93573673, 0.93921913,        nan,\n",
      "       0.9529901 , 0.94436354, 0.94475921, 0.9127851 , 0.94183092,\n",
      "       0.91318073,        nan, 0.9478458 ,        nan, 0.94262233,\n",
      "       0.94768751, 0.95077415, 0.95069498, 0.95053659, 0.94475922,\n",
      "              nan,        nan,        nan,        nan, 0.95077403,\n",
      "              nan, 0.91136057, 0.93787369, 0.94998274,        nan,\n",
      "       0.94333471, 0.93937738,        nan, 0.9475292 , 0.9529901 ]), 'split4_test_ROC-AUC': array([       nan, 0.93953025,        nan, 0.94522883,        nan,\n",
      "              nan, 0.90549696, 0.936206  , 0.93984675,        nan,\n",
      "       0.95409342, 0.94443735, 0.94538715, 0.90882105, 0.94309168,\n",
      "       0.90620926,        nan, 0.94807816,        nan, 0.94396242,\n",
      "       0.94871127, 0.95179804, 0.95068992, 0.94958198, 0.94483319,\n",
      "              nan,        nan,        nan,        nan, 0.95140237,\n",
      "              nan, 0.90628829, 0.93810558, 0.95140227,        nan,\n",
      "       0.94443723, 0.9408757 ,        nan, 0.94704924, 0.95409342]), 'mean_test_ROC-AUC': array([       nan, 0.92931112,        nan, 0.93510429,        nan,\n",
      "              nan, 0.90086754, 0.92742748, 0.93029244,        nan,\n",
      "       0.94252782, 0.93413878, 0.93488271, 0.90213383, 0.93342643,\n",
      "       0.9012949 ,        nan, 0.93686127,        nan, 0.93296747,\n",
      "       0.93670299, 0.94037515, 0.94020101, 0.93877648, 0.93461364,\n",
      "              nan,        nan,        nan,        nan, 0.93978951,\n",
      "              nan, 0.9005035 , 0.92834559, 0.9396154 ,        nan,\n",
      "       0.93469272, 0.93015002,        nan, 0.93686124, 0.94252782]), 'std_test_ROC-AUC': array([       nan, 0.01951168,        nan, 0.02071185,        nan,\n",
      "              nan, 0.01660506, 0.01950454, 0.02010795,        nan,\n",
      "       0.02290338, 0.02104245, 0.02083703, 0.01638865, 0.01903593,\n",
      "       0.01753891,        nan, 0.02230285,        nan, 0.02156001,\n",
      "       0.02198746, 0.02201536, 0.0212614 , 0.02340767, 0.02081491,\n",
      "              nan,        nan,        nan,        nan, 0.02326907,\n",
      "              nan, 0.01596322, 0.01899514, 0.02185712,        nan,\n",
      "       0.01982368, 0.02019726,        nan, 0.02135154, 0.02290338]), 'rank_test_ROC-AUC': array([27, 20, 27, 11, 27, 27, 25, 22, 18, 27,  1, 15, 12, 23, 16, 24, 27,\n",
      "        8, 27, 17, 10,  3,  4,  7, 14, 27, 27, 27, 27,  5, 27, 26, 21,  6,\n",
      "       27, 13, 19, 27,  9,  1], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Assuming you have already applied SMOTE on the training set\n",
    "# X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "# Define the scoring metrics\n",
    "scoring = {'F1': make_scorer(f1_score, average='binary'), \n",
    "           'ROC-AUC': make_scorer(roc_auc_score, multi_class='ovr', average='macro')}\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter distributions for RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'n_estimators': (100,125, 150, 175,200, 250),  # Randomly sample number of trees from 100 to 300\n",
    "    'max_depth': [None, 10, 20, 30],     # Can still specify discrete values\n",
    "    'min_samples_split': randint(2, 10),  # Randomly sample from 2 to 10\n",
    "    'min_samples_leaf': randint(1, 5),    # Randomly sample from 1 to 5\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Discrete values remain\n",
    "    'bootstrap': [True, False]        # Discrete values remain\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV with multiple scoring metrics\n",
    "random_search = RandomizedSearchCV(estimator=rf_classifier, \n",
    "                                   param_distributions=param_distributions, \n",
    "                                   n_iter=40,  # Number of random combinations to try\n",
    "                                   scoring=scoring, \n",
    "                                   cv=5, \n",
    "                                   refit='F1',  # Optimize for F1 score\n",
    "                                   verbose=1, \n",
    "                                   n_jobs=-1,  # Use all cores\n",
    "                                   random_state=42)\n",
    "\n",
    "# Fit the random search on the training data\n",
    "random_search.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Print the best hyperparameters and F1 score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best F1 Score:\", random_search.best_score_)\n",
    "\n",
    "# You can also check the results for both metrics (F1 and ROC-AUC)\n",
    "results = random_search.cv_results_\n",
    "print(\"Random Search Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "175fc1d1-78f0-4bfb-9711-59f336b0b016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayur\\AppData\\Local\\Temp\\ipykernel_7272\\1398381167.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['y'] = df['y'].replace({'yes':1, 'no':0})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8925842696629214\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      7898\n",
      "           1       0.52      0.61      0.56      1002\n",
      "\n",
      "    accuracy                           0.89      8900\n",
      "   macro avg       0.73      0.77      0.75      8900\n",
      "weighted avg       0.90      0.89      0.90      8900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Best Parameters: {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 175}\n",
    "#Best F1 Score: 0.942631981788919\n",
    "\n",
    "df = pd.read_csv(\"dataset2.csv\")\n",
    "df = df.drop(columns=['marital', 'loan', 'education', 'default', 'poutcome'])\n",
    "df['y'] = df['y'].replace({'yes':1, 'no':0})\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Smote for training set\n",
    "smote = SMOTE(random_state=54)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=54, class_weight='balanced',\n",
    "                                       bootstrap=False, max_depth=None, max_features='sqrt',\n",
    "                                       min_samples_leaf=1, min_samples_split=3,\n",
    "                                       n_estimators=175)\n",
    "rf_classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ba4344ec-706e-40de-b3cb-6f11dc7042ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Training Classification Report:\n",
      " {'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 31589.0}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 31589.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 63178.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 63178.0}}\n",
      "Test Accuracy: 0.8925842696629214\n",
      "Test Classification Report:\n",
      " {'0': {'precision': 0.9498444790046656, 'recall': 0.9279564446695366, 'f1-score': 0.9387728961188677, 'support': 7898.0}, '1': {'precision': 0.5194256756756757, 'recall': 0.6137724550898204, 'f1-score': 0.5626715462031107, 'support': 1002.0}, 'accuracy': 0.8925842696629214, 'macro avg': {'precision': 0.7346350773401706, 'recall': 0.7708644498796785, 'f1-score': 0.7507222211609892, 'support': 8900.0}, 'weighted avg': {'precision': 0.9013860923826826, 'recall': 0.8925842696629214, 'f1-score': 0.8964298003193634, 'support': 8900.0}}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance on training set\n",
    "y_train_pred = rf_classifier.predict(X_train_smote)\n",
    "train_accuracy = accuracy_score(y_train_smote, y_train_pred)\n",
    "train_report = classification_report(y_train_smote, y_train_pred, output_dict=True)\n",
    "\n",
    "# Evaluate performance on test set\n",
    "y_test_pred = rf_classifier.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Training Classification Report:\\n\", train_report)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test Classification Report:\\n\", test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd47658b-c67f-458e-9190-6b0ada6b456e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
